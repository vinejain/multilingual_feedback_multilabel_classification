{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_CFA_v2ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7c77965b80c43c3a3e096efcced68dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd0349f390ed4f19b86e04578ae991ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9038bbbca0d643c3a33bb08f30a1a586",
              "IPY_MODEL_e9c9890bb0e74c138719f5a495f6f324"
            ]
          }
        },
        "dd0349f390ed4f19b86e04578ae991ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9038bbbca0d643c3a33bb08f30a1a586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34a675a6cb174d4dabcd6fd83a5f427f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f34f96bd9bc4968a02f8996d59d3ba9"
          }
        },
        "e9c9890bb0e74c138719f5a495f6f324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a96ad69b5d994a95b2b67c84ef4a1625",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 9.68kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82c94afbbf9f4fb5878f59901e46140d"
          }
        },
        "34a675a6cb174d4dabcd6fd83a5f427f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f34f96bd9bc4968a02f8996d59d3ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a96ad69b5d994a95b2b67c84ef4a1625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82c94afbbf9f4fb5878f59901e46140d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e6bb57707ef44c391b136e2e2a2a175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8491c42539d3462e82668db0c9a0bf16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f6879bec1544e28ba39fec4cad6050e",
              "IPY_MODEL_701a80bc430a482fb6d85d451924de05"
            ]
          }
        },
        "8491c42539d3462e82668db0c9a0bf16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f6879bec1544e28ba39fec4cad6050e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1e403f08e69497f83ce1430fbc063fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc6fd2208223478c9090e28906a528fd"
          }
        },
        "701a80bc430a482fb6d85d451924de05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99596628cff44879a50bd023556379d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 577kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00f65e6799ac41aba1b238bd87426577"
          }
        },
        "d1e403f08e69497f83ce1430fbc063fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc6fd2208223478c9090e28906a528fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99596628cff44879a50bd023556379d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00f65e6799ac41aba1b238bd87426577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "243bc0364e744804a65c884ad8684ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8db5aed8b3ff46f89895a4df7a6602cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49920be1a20742ae8b72564db7b8fe43",
              "IPY_MODEL_767a342a38a74daab47c5d8644b26987"
            ]
          }
        },
        "8db5aed8b3ff46f89895a4df7a6602cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49920be1a20742ae8b72564db7b8fe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a2dc55265a4244a881e8fd157267ede4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1e1f72664fc46028ded53af91ba3bf6"
          }
        },
        "767a342a38a74daab47c5d8644b26987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_659a675fbc054d60af0cec2d3dd40d07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 43.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bfb25862dd849209671d2b0e2c38a25"
          }
        },
        "a2dc55265a4244a881e8fd157267ede4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1e1f72664fc46028ded53af91ba3bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "659a675fbc054d60af0cec2d3dd40d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bfb25862dd849209671d2b0e2c38a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinejain/multilingual_feedback_multilabel_classification/blob/master/BERT_CFA_v2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt4sr6P-wC7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "31d698c2-372d-4b41-a326-487e78cdcbb2"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/6b/e705f03eb23b9002d01b942423d3e5f954acd9b20d9dfd5ee25868f44893/bert_tensorflow-1.0.3-py2.py3-none-any.whl (68kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWiS36j18E62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1346b9fd-7605-4f0d-ddad-e36cfd0a221d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7imIW85JOMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "5bcdd95a-f9c0-4a62-99f8-96b50bc173d3"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.33)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkEsRHdV8fUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a16d1268-cc81-4d7f-f4f2-ef1052ef99c7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQwpsvpJck2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1599cdb4-2336-4ded-ffb7-e8c05ab4606d"
      },
      "source": [
        "pip install apex"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting apex\n",
            "  Downloading https://files.pythonhosted.org/packages/31/b6/923de12ffcc2686157d7f74b96396b87c854eaaeec9d441d120facc2a0e0/apex-0.9.10dev.tar.gz\n",
            "Collecting cryptacular\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/d6/a82d191ec058314b2b7cbee5635150f754ba1c6ffc05387bc9a57efe48b8/cryptacular-1.5.5.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/83/459decec1dd2c14d60f9a360fff989c128abe545a1554a1da64b054a55d4/zope.sqlalchemy-1.3-py2.py3-none-any.whl\n",
            "Collecting velruse>=1.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/d9/e18b5c98667c45f5dd1a256d72168ea5ff68f0025fc5b24be010f2696ca3/velruse-1.1.1.tar.gz (709kB)\n",
            "\u001b[K     |████████████████████████████████| 716kB 12.4MB/s \n",
            "\u001b[?25hCollecting pyramid>1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/4f/6fe39af43fadc6d6c12f4cff9ed438f4fed20245614170959b38fe9f762d/pyramid-1.10.4-py2.py3-none-any.whl (325kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 36.2MB/s \n",
            "\u001b[?25hCollecting pyramid_mailer\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/c3/0ce593179a8da8e1ab7fe178b0ae096a046246bd44a5787f72940d6dd5b2/pyramid_mailer-0.15.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from apex) (2.23.0)\n",
            "Collecting wtforms\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/31/614fc7dc7d76005b0acb8c0c8920d962b83d7422b4ba912886dfb63f86ff/WTForms-2.3.3-py2.py3-none-any.whl (169kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 42.2MB/s \n",
            "\u001b[?25hCollecting wtforms-recaptcha\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/b0/42021ab061b768e3e5f430466219468c2afec99fe706e4340792d7a6fab4/wtforms_recaptcha-0.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from cryptacular->apex) (49.2.0)\n",
            "Collecting pbkdf2\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c0/6a2376ae81beb82eda645a091684c0b0becb86b972def7849ea9066e3d5e/pbkdf2-1.3.tar.gz\n",
            "Collecting transaction>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/06/17b311f04ee623bea66f2f2a93a1b5691e383278d7d30980bba3f1c03ce9/transaction-3.0.0-py2.py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=0.7 in /usr/local/lib/python3.6/dist-packages (from zope.sqlalchemy->apex) (1.3.18)\n",
            "Collecting zope.interface>=3.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from velruse>=1.0.3->apex) (1.3.0)\n",
            "Collecting anykeystore\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/dc/c4399c0e6b835710763705220f9c37681683f950678db799a5c7eda9e154/anykeystore-0.2.tar.gz\n",
            "Collecting python3-openid\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/a5/c6ba13860bdf5525f1ab01e01cc667578d6f1efc8a1dba355700fb04c29b/python3_openid-3.2.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 38.5MB/s \n",
            "\u001b[?25hCollecting plaster\n",
            "  Downloading https://files.pythonhosted.org/packages/61/29/3ac8a5d03b2d9e6b876385066676472ba4acf93677acfc7360b035503d49/plaster-1.0-py2.py3-none-any.whl\n",
            "Collecting translationstring>=0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/98/36187601a15e3d37e9bfcf0e0e1055532b39d044353b06861c3a519737a9/translationstring-1.4-py2.py3-none-any.whl\n",
            "Collecting webob>=1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/3c/de37900faff3c95c7d55dd557aa71bd77477950048983dcd4b53f96fde40/WebOb-1.8.6-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 38.6MB/s \n",
            "\u001b[?25hCollecting zope.deprecation>=3.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/26/b935bbf9d27e898b87d80e7873a0200cebf239253d0afe7a59f82fe90fff/zope.deprecation-4.4.0-py2.py3-none-any.whl\n",
            "Collecting hupper>=1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/48/7f/06ace28143b2cb3a4b14c9d9e5165741d2d133ef331b616acf47ab5c3517/hupper-1.10.2-py2.py3-none-any.whl\n",
            "Collecting plaster-pastedeploy\n",
            "  Downloading https://files.pythonhosted.org/packages/11/c4/0470056ea324c7a420c22647be512dec1b5e32b1b6e77e27c61838d2811c/plaster_pastedeploy-0.7-py2.py3-none-any.whl\n",
            "Collecting venusian>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/92/3d522a710867168ee422a0ffbd712c425ece937aaeec4381497a59e24faf/venusian-3.0.0-py3-none-any.whl\n",
            "Collecting repoze.sendmail>=4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/98/c5c64dc045b7c45858c391d04673a0f2748acef8e0eea4f2989b22220f97/repoze.sendmail-4.4.1-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2020.6.20)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from wtforms->apex) (1.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from python3-openid->velruse>=1.0.3->apex) (0.6.0)\n",
            "Collecting PasteDeploy>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/18/196e5070ced83bb81edd83c79545232d1d2ec55e3a099a146a3333244a6b/PasteDeploy-2.1.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: cryptacular\n",
            "  Building wheel for cryptacular (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.5.5-cp36-abi3-manylinux2010_x86_64.whl size=47558 sha256=f085f2700c651f2f5edc808a28022e86f884818a6b4786613be2c4ba0898a1b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/79/bc/1eec7120c3ff9b0a2c7ad94d1626abc3388688e2ed7a45878f\n",
            "Successfully built cryptacular\n",
            "Building wheels for collected packages: apex, velruse, pbkdf2, anykeystore\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-cp36-none-any.whl size=46467 sha256=9b4b2935d2c5126e038ce1a6513faa17e83352a960d2c2409294b6c79ce9b196\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/4c/4b/2990cf86a29c679ae4bd5f4de5723aa8a4af107721089c9a55\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-cp36-none-any.whl size=50924 sha256=1c8564af1112d5b6b38c32c2e1a9fd6b29dc168477a7e7575a30db2969e9a0f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/65/9e/b805aad8ec3a359591c497b257dabe911f305d285b5d8a13cc\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-cp36-none-any.whl size=5103 sha256=93196c9ceeeb0849104be21809c85f9e03107cd5b6ab98c463ac09cda23f2aea\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/62/b9/0bf3a68f2111e169253ec4d2bbdc303c46777b7fc99bbbf230\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-cp36-none-any.whl size=17026 sha256=36e4458bb319a1756c34f9a5acc2f6e1aaccfece53fae6198910bdb7f20eba00\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/a9/b2/f79f84cbee6613c9edce6d98b9e1410c1d41d38953bd94eed2\n",
            "Successfully built apex velruse pbkdf2 anykeystore\n",
            "Installing collected packages: pbkdf2, cryptacular, zope.interface, transaction, zope.sqlalchemy, plaster, translationstring, webob, zope.deprecation, hupper, PasteDeploy, plaster-pastedeploy, venusian, pyramid, anykeystore, python3-openid, velruse, repoze.sendmail, pyramid-mailer, wtforms, wtforms-recaptcha, apex\n",
            "Successfully installed PasteDeploy-2.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.5.5 hupper-1.10.2 pbkdf2-1.3 plaster-1.0 plaster-pastedeploy-0.7 pyramid-1.10.4 pyramid-mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-3.0.0 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.6 wtforms-2.3.3 wtforms-recaptcha-0.3.2 zope.deprecation-4.4.0 zope.interface-5.1.0 zope.sqlalchemy-1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df0EAyb8ot3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5a47523-3e14-449e-d487-8facc1ccba5b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bzRcy6nL57J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "66aa815b-b6a4-4781-c161-23b10ccd0a0e"
      },
      "source": [
        "#pip uninstall apex"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling apex-0.9.10.dev0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/apex-0.9.10.dev0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/apex/*\n",
            "Proceed (y/n)? n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu4baW6eL_a-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "75bea889-b650-411d-d758-51a6da698180"
      },
      "source": [
        "!git clone https://www.github.com/nvidia/apex"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "warning: redirecting to https://github.com/nvidia/apex.git/\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 7425 (delta 7), reused 3 (delta 1), pack-reused 7400\u001b[K\n",
            "Receiving objects: 100% (7425/7425), 13.91 MiB | 12.79 MiB/s, done.\n",
            "Resolving deltas: 100% (5007/5007), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGCNm5T8tzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c7aac57-b7a8-4738-bdc8-f9c8b6ec8e46"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVQV_GiMP39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78778ed6-fd3d-40b9-8bc6-9c7243fa8f58"
      },
      "source": [
        "cd apex"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em9Br06HMQUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "346ed068-4f51-4ec6-9a1c-ecd9f2b059af"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating apex.egg-info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/apex\n",
            "copying apex/__init__.py -> build/lib/apex\n",
            "creating build/lib/apex/RNN\n",
            "copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "creating build/lib/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "creating build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "creating build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "creating build/lib/apex/contrib\n",
            "copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "creating build/lib/apex/amp\n",
            "copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "creating build/lib/apex/normalization\n",
            "copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "creating build/lib/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "creating build/lib/apex/mlp\n",
            "copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "creating build/lib/apex/pyprof\n",
            "copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "creating build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "creating build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "creating build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "creating build/lib/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "creating build/lib/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "creating build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "creating build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "creating build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "creating build/lib/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "creating build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __path__\n",
            "creating dist\n",
            "creating 'dist/apex-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg\n",
            "Extracting apex-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Finished processing dependencies for apex==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov3SFh6_KCZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zope.interface import implementer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0udgtsLIqqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import pdb\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import apex\n",
        "from sklearn.model_selection import train_test_split\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3JmRFJbPNpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "ab99def4-9d6a-4aa9-9db6-fb8c173782d5"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForNextSentencePrediction\n",
        "\n",
        "BERT_CLASS = BertForNextSentencePrediction"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGDJ_jwjPT8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0d0dd89a-46f1-4b40-b4ab-b111ae0df390"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU1HkjYK262n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3ead37e9-766d-4fb6-8b31-b6936561dcca"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "!unzip the file\n",
        "!unzip cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 01:33:18--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 74.125.71.128, 74.125.140.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M  79.1MB/s    in 5.7s    \n",
            "\n",
            "2020-08-11 01:33:24 (67.8 MB/s) - ‘cased_L-12_H-768_A-12.zip’ saved [404261442/404261442]\n",
            "\n",
            "unzip:  cannot find or open the, the.zip or the.ZIP.\n",
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: cased_L-12_H-768_A-12/\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEvpeXC3A4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d4180d3e-22cc-4c09-b194-8d90af5440c9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex\t\t\t   csrc      README.md\n",
            "apex.egg-info\t\t   dist      requirements_dev.txt\n",
            "build\t\t\t   docs      requirements.txt\n",
            "cased_L-12_H-768_A-12\t   examples  setup.py\n",
            "cased_L-12_H-768_A-12.zip  LICENSE   tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd8oIUg67ezi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a1b497e-ae3b-461b-df7f-68605d8753cd"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52228zog-Kt4",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/51417533/stuck-in-datalab-directory-cant-navigate-to-my-desired-directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxe5jaSL7iDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af39bbf8-2c76-403d-aba7-5f0e777d6807"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMTnm8BzMzPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA_PATH=Path('../Toxic_comment/')\n",
        "DATA_PATH=Path('/content/drive/My Drive/Data/toxic_comment_classification_challenge/')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "#PATH=Path('../Toxic_comments/')\n",
        "PATH=Path('/content/drive/My Drive/Data/toxic_comment_classification_challenge/')\n",
        "PATH.mkdir(exist_ok=True)\n",
        "\n",
        "CLAS_DATA_PATH=PATH/'class'\n",
        "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "model_state_dict = None\n",
        "\n",
        "# BERT_PRETRAINED_PATH = Path('../trained_model/')\n",
        "#BERT_PRETRAINED_PATH = Path('/content/drive/My Drive/Toxic_comment/uncased_L-12_H-768_A-12/')\n",
        "BERT_PRETRAINED_PATH = Path('/content/uncased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/cased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/uncased_L-24_H-1024_A-16/')\n",
        "\n",
        "\n",
        "# BERT_FINETUNED_WEIGHTS = Path('../trained_model/toxic_comments')\n",
        "\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH\n",
        "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)\n",
        "\n",
        "# output_model_file = os.path.join(BERT_FINETUNED_WEIGHTS, \"pytorch_model.bin\")\n",
        "\n",
        "# Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQPLIcmUM368",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "args = {\n",
        "    \"train_size\": -1,\n",
        "    \"val_size\": -1,\n",
        "    \"full_data_dir\": DATA_PATH,\n",
        "    \"data_dir\": PATH,\n",
        "    \"task_name\": \"toxic_multilabel\",\n",
        "    \"no_cuda\": False,\n",
        "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
        "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
        "    \"max_seq_length\": 512,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"eval_batch_size\": 32,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"num_train_epochs\": 4.0,\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"no_cuda\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"seed\": 42,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"optimize_on_cpu\": False,\n",
        "    \"fp16\": False,\n",
        "    \"loss_scale\": 128\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6KwClElf5a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm5E8JOof9eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14cgH-_Tf_96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError() \n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3R9Gvj1gEZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "    \n",
        "    \n",
        "    def get_train_examples(self, data_dir, size=-1):\n",
        "        filename = 'train.csv'\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"train\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"train\")\n",
        "        \n",
        "    def get_dev_examples(self, data_dir, size=-1):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        filename = 'val.csv'\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"dev\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None)[0].values)\n",
        "            #self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"test_labels.csv\"),header=None)[0].values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=True):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[0]\n",
        "            text_a = row[1]\n",
        "            if labels_available:\n",
        "                labels = row[2:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKgB3wGXgH9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(float(label))\n",
        "\n",
        "#         label_id = label_map[example.label]\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBTK8WpgMJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqQKucagPNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)\n",
        "\n",
        "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "\n",
        "\n",
        "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
        "    \"Computes the f_beta between `preds` and `targets`\"\n",
        "    beta2 = beta ** 2\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    y_pred = (y_pred>thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    TP = (y_pred*y_true).sum(dim=1)\n",
        "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
        "    rec = TP/(y_true.sum(dim=1)+eps)\n",
        "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
        "    return res.mean().item()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiT4QUhPgR8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GZEwawagT1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ba89bcf-55a8-41e6-9edb-f969a8542e45"
      },
      "source": [
        "processors = {\n",
        "    \"toxic_multilabel\": MultiLabelTextProcessor\n",
        "}\n",
        "\n",
        "# Setup GPU parameters\n",
        "\n",
        "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "#     n_gpu = 1\n",
        "else:\n",
        "    torch.cuda.set_device(args['local_rank'])\n",
        "    device = torch.device(\"cuda\", args['local_rank'])\n",
        "    n_gpu = 1\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
        "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:35:19 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLmOKpR7gV8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwVbVbB2gZXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args['seed'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4evhA1KgcOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_name = args['task_name'].lower()\n",
        "\n",
        "if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrmsZzDmgeVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processor = processors[task_name](args['data_dir'])\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib8pjuuOhtQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a1801e8-a2fb-44c1-974c-97cf89a62a3f"
      },
      "source": [
        "label_list"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id\\ttoxic\\tsevere_toxic\\tobscene\\tthreat\\tinsult\\tidentity_hate',\n",
              " '00001cee341fdb12\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0000247867823ef7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00013b17ad220c46\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00017563c3f7919a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00017695ad8997eb\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0001ea8717f6de06\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00024115d4cbde0f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000247e83dcc1211\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00025358d4737918\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00026d1092fe71cc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0002eadc3b301559\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0002f87b16116a7f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0003806b11932181\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0003e1cccfd5a40a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00059ace3e3e9a53\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000634272d0d44eb\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000663aff0fffc80\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000689dd34e20979\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000834769115370c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000844b52dee5f3f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00084da5d4ead7aa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00091c35fa9d0465\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '000968ce11f5ee34\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0009734200a85047\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00097b6214686db5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0009aef4bd9e1697\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000a02d807ae0254\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000a6c6d4e89b9bc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000bafe2080bba82\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000bf0a9894b2807\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000c50dceb1eed2b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000c9b92318552d1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000ce41d86f2b886\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000cf60dbaed8c02\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000d4f120d5a7303\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '000d60becb7d1a67\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000fc381d4895598\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '000ff37cf57ab537\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001068b809feee6b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0011c58fcfd6bf91\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0011cefc680993ba\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0011ef6aa33d42e6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0012706ac77a7b37\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0012bb72f20ae971\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0012bbcbd6958302\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00137446b1aec28c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0013a435effa29bd\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0013be435187e84f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0013fed3aeae76b7\\t1\\t0\\t1\\t0\\t1\\t1',\n",
              " '001411adf8f1dd82\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001421530a1aa622\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001426f56de6a49b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00148cabab3f0abd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0015d9af6dbc03c0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00166b5f5bf2d758\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0016909ad784fe8d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0016b94c8b20ffa6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0016ec04bb0f869a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00177176f33f587e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0017d4d47894af05\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '001804717513d860\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0018af86a1bdfef3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0019400581a6fe32\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00199e012d99a8b9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001a9a0fce445525\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001acc29b248cb6d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001ade31463efdfe\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001af79497a01e91\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001bb624469de607\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001c368c738a814f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001c86f5bceccb32\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001cba5e79b6b91e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001ceacfd4ffa469\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001ceebc43e65027\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001d2f65ea6f4163\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001d39c71fce6f78\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001d739c97bc2ae4\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '001deac5571d5186\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001e131e1a08845a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001eba8bbe728e54\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '001ed6d4be00614b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '001eff4007dbb65b\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '001f1f993acff9a3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0020376025dd8092\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002046a2e5669735\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002093eb829e4e1b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00209bd924d80a3e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0020baa22b95d1b0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0020e1f3fafd4b17\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0020f1b79913e7c0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0021e57e6b9cb3d9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0021f7c457937f18\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002261b0415c4f9d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0023317d123b6fcb\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00234e493cedb3e1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0023f3f84f353bce\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '002586bdf3280356\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0025a91b6955f1a5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0025c49d87d9a18f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00260d8dfcc29827\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0026c91011e3ae35\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0027160ca62626bc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0027c21bc4637efd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00281611ff9c0123\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0028b002aacc20cc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0028bca06339e02f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0028c5110f1f896b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00291ce25a490740\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00293511a845d344\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '002a3ebaaa51f17a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002af5c4c7f08722\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '002b3c51eb2cb207\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002b41238214233e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002b92bbe21a6af4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002c586b0af3792c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002cd3ed1c9c7555\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002eef919d2f8410\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '002fb627b19c4c0b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '002fec87c1465bd8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003044a2c35274b6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0030a3760c6e27f3\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0030e3ba49006440\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00314b8e8314b445\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00316955ef4b0fee\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0031c900f2018470\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0031d0649f4a266b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0031db73bf0939c3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00325303c23588a4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003260a50813dba9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0032e594263182fc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00340e8231a91349\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00372dfdd531fc6c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0037738477182b8e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00379bb7b2b2e644\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00380df890f6b894\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00385b9bffdeb9c8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0038a47d8f1bb327\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003994b922637eee\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003abee7e2ed7b4b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003b169a420e3757\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003bb366e674a9d4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003c6a7652d31202\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003c73565c434b4b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003d1b257aba9a9e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003d82f5e461ad76\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003d8674aeeec5ec\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003deb1d3dff6793\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003e3cb0578f451e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003ea5201eae8fec\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003eba3ef992ee20\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003ec3dbae5dc8a7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003f43cdfcaaed40\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003fc0a59f6f977f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003fc837ea217bc2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '003fcf8c7df1b038\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '003fd5c24c970c1c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004078790485c9ea\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00410d7506f22d90\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004110369dcf5306\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00418320f2620bac\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00419d13372bdd27\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0041dc272b8579a9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '004248aaf2a0405d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00426fbaf380b88a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004278af07e050ea\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0042a95dc2b6a0a8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00434db6be41a019\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0043b6e76433c3b6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0043c91b8619691c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0043d859042ff14c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00441d96a027ea2d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004515df90b06ef9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '004540f1a3bba137\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00463993d4325375\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004651d6884295bf\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0046db897eaa12e7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0046f41333aebfe7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0047582c40509d2d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004793abaf67dd8e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004902b29a55acae\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00491682330fdd1d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00499c7740639d54\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0049aa24a742d72d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0049b89b2b87ab4f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004a5c6fc6ad7ee1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '004c7175222a0874\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004d08f9a5ac222c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004f5138a0806616\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '004f9b912485577f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00500c89c524d462\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00501b570d5f088e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0052080181d4bb59\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00525672cc446424\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0052e5508d893965\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00531c5e44a0f7b1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0054acabba861c90\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0055d8bd8cc6bdcf\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005632783e0a710e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0056a1878a9ac061\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0057b1b22bb07ff4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0057d0636238fbdc\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00581f9073b44b38\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00584a461ec2bb9c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005875658c15a8dc\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00587ac3969af38c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005952536ffa515d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0059770b56a0a96b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005a70436655b05c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005ad5a11d230fe1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005bb8c85ea8239c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005bd529d8419f82\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005c9fb982881668\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005cb5a153394bf7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005cbdff132bc6d6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005d15b15b4c5f63\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005d4e5881163749\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005dc750df10832c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '005e7386ac2cbb4f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005f2ece64799178\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '005f47397e07e12f\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '005fcbdbea0017f7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0060bb88a6a19887\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0060ffb1174942c8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0061e98945132728\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00628908eb19d174\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0062f4a9f84afcd6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006370c073d76402\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006394f6e66d362d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0064b3e9f65f78e7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0064b4200305c664\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0065324079670f4d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0065ab247b1c5b8f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0065dcaa766efd7e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006622a9f635ace3\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0066f2bd2c5a5cf7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0066fcd6fc78151a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0068183d5334c05b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006879d1b65f840a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0068a2513b819cbd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0068ef7921fa5b2e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0069e387068f362f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0069e74a5302bf10\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0069f92051de8d3d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006a26a98a6170e9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006a703e116e7ee8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006b7fdf64a25aef\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006beb8649b70d99\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006bee650e550b76\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006c132f3df89e6e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006c2953a63bd221\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006d7b5d3ad1e8d6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006ed2d32c694d2f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '006ef62bc69dbda6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '006f1b719aa6010b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007009b9d4b62e19\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007021b91a4a3cf7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0070bebd6e8fd4af\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0070c68c9a05a502\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0071940212267fea\\t1\\t0\\t1\\t0\\t0\\t0',\n",
              " '0072b9c3697ab8cc\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '0072f0af33e59b26\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0073068ecad94106\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007347667889fc34\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00741a5b7cbd227e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0074e9e50532d8fa\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00755db353a12f44\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0075651cd329225d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0075b81a118c85f9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0075ff203b6e7d6d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00760322e8084f55\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00768ff5e3f93322\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0076a6c9cc70c2ea\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00772869541790fe\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0077446717b5226d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00789fd8ef55a757\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0078e03e2556b416\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007931b28cca3e85\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00795a46cc1c7816\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00798254f8b62857\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0079d764fbad47d1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007ab9116b865d64\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007acf127f807de4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007aec85ba5ab379\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007b7700996e28f1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007c5396123aab32\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007cbba20a6abc0b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007d75123ac09c87\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007d79de592ecb74\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007e29f0315dd5f2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007e9c51523a40f2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007eebc1375cf0c0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007f127a7114cb74\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007f1a7b05383fff\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007f274b0b0aa04f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007f4366a62d5970\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '007f494cc22876c3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '007ff2e73d804a5f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00800dd64ee65ee8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00806e8b8e84b0f2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0081163fbdf7269c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008171d59b2f6949\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00818de3ad57b3ba\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0081b14d79f54b31\\t1\\t0\\t1\\t1\\t0\\t0',\n",
              " '008226521a76c440\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008421f7a1b169b9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00842d1024b19972\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '0084725fe3a49a4f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0085bb3cfa3babc6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00862b4e7e1e6eb7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0086df2fc0ce8b76\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0087665aec930ed9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0087dec30e0c0d62\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0087e4e52e4f105b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00881f5dfc5626a1\\t1\\t0\\t0\\t0\\t1\\t0',\n",
              " '0088d1c06e3c7734\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0089318e8a1dc9ce\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0089a271e952fb95\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008a15f5a65c4b69\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008a21dc1fad97a3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008a5351d86ee94f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008ab673e129ea7e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008aefc9605919fb\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '008b6a9b1054db7b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008b8db2b48dc0b5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '008bb5836fcd640b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008be84e2a8476de\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '008c3875d1e3db70\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '008cf09d527a611b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008d544fc61fb478\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '008d6be37c6d8e70\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008d6ec17d57e6e3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008df6d9bd6f9f45\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008e56dc71d2c1ec\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008eb47c4684d190\\t1\\t0\\t0\\t0\\t1\\t0',\n",
              " '008ed4db83a4fafe\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008eddd0a489b8b6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008ef340d0a20848\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008f06d591c9ac2c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008f0bf274119823\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008f404094afbf21\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '008fd5b7e6024e22\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00921de00e9bc0aa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009361ecb09ca541\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00936d41be11f46f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00940e2afabcd625\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00941d55104fbd87\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009441b12da77fe8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0094f667bb261b9c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00950acfec3911fe\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00950f0fae33869f\\t1\\t0\\t1\\t0\\t1\\t1',\n",
              " '00956af27814a607\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0095b512b3dbcac0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0095e2f6797e9b88\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009658dc3a37e669\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00966e21a96759a4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00968dd9cdffc1a8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0096a7935b878320\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0096c1d0617cd004\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00970834255b5d67\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00978e3b8f542b9b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009846b7926aa0c2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00991697be5ed76a\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '00999cc600fdad60\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0099cb91111b42ef\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0099d12446df60da\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0099d1b53935a4f4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009a485368ce0858\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009b2c6569a0da06\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009b7b59c32fe0d8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009b7eb911c2bcf0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009ba60f01432c26\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009c9e3ef568aefb\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009d713f2af2ad50\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009d7311eccb38fd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009e413eaef8617e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '009eb09483e46b77\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '009f03897f22b7a7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a00728aa99a582\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a02064e4c420d3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a07ba2a7e7ea19\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a0dc99b6217cf1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a15da9ed162f16\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a19ec49f0c9b09\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a34c46213caab9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a3bee4e98b9737\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a3bfcf9d1e85f2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a4660f86ce9337\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a475913f684e36\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a4afe1cce113c5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a4c2b6f82b609f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a4d561acc1ca33\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a588493d0180db\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a5f35a6bd85da5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a66226fbcd44c5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a74b2b2b85cb17\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a7a3ddf7f5878b\\t1\\t0\\t1\\t0\\t1\\t1',\n",
              " '00a7b8f665496302\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a82e724108843e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a858641647ace9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00a890459c4f8243\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a89f102fec04ae\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00a8d7038fcfa9d8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ac1c2ef1f700f0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ace04912f84306\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ad0323d9b31f21\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ad2ddf3b55bc2f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ad5a7363b9563c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ade84de7dcf996\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ae4845fb54114c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ae5c763bca3cee\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ae9d18545a8c16\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00af4bc0412fc6fa\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00af68abf323d3b4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b160f1ff46baff\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b1d1e436efc9b5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b376c7b30bc9f1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b3813b966af7e8\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b39b07adb77972\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b553377d7d9832\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b568d3b0f61a37\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b5a437917e8994\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b5eff67599534a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b615ec836f802c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b677d38f1c947c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b68ad3b5608c61\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b6d450559e2478\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b706aa7e74b4a6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b771e66da2151c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b8c20aae3a3172\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b8c894575e5fd0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b8ce2634736c91\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00b9325c635d7de1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00b99df10f7b0058\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ba154fb00f8af2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00baba1768d3b7fb\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00baf467ffc792af\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bafd62adabbc6c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bbaedc072b0d95\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bc58bfddedee17\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bc7aab9bc97766\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bc81c8feddad5a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bca827b39dd487\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bcbc1dffa26152\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bcfa4c0af364e0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bd1704512eea08\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bd66c9ef023f41\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bd73bc3851fc52\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bdb71dbe1928ff\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bddb500adc9f35\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bdde697c68529b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00be095c193612db\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00beaf985926d722\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bed655b5465fe8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bee0148b44976e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bf247e6eaedb8f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00bf582e21b0f515\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00bfb2da95778a19\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c00fc9f8155e5d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c0239ad67647a2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c046cb3a07cd38\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c056846749159a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c070a4753b0fa3\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '00c0c0e0b16ef845\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c0c355b819c5c2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c1d48675fae321\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c33a48ebd3ae81\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c36a3675b03219\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c3dc659af5a042\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c51e9624561017\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c55a354b26db72\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c5aa1a91ba667e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c7134e4853d15c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00c75e9fc79f74ca\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c771f9c00294fa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c79ce21ee18afb\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00c8d5a33c6a7b2f\\t1\\t0\\t1\\t0\\t1\\t1',\n",
              " '00c9f080b2d9365b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cab4494f8a632c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00caf65e2df4aa20\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cb17575d610e9b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cb262ba14f5cdb\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cb2e7eeb88fdb8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cb56bad92634ea\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cbaa698658db93\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cbc079f3be0661\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cce03a936b2f15\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ccf59ab228a528\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cd1030c4bba2db\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cdc8839cd25c6a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cdea5b3e68fef0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ce3aa27fdf41c9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ceb2394da35118\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cee7ebce1912f8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cf42a303310e5b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cf793d401aed8b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cf862de0929a0d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00cf8932eb2dcdcc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00cfd946fcc6f8ed\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d06c6557280d2f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d08307c9439df8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d1a5dca34578b1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d1f3c7d05d2cc1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d249ce16467afd\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d251f47486b6d2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d257fb950fc7d6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d28e652c955927\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d2aca8d65aa590\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d37effb6d090db\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d38fb2b8093d91\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d3c9849083dd98\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d43781a4b1a870\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d57b29c91e12e4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d6648608e14493\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d6e0df703e130c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d6f3966387a25f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d7f0eb5cb39817\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d85af192f8bb8d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00d8cdaf1a2c37a1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00d9b5f67196adc4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00da4635c592bebc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00daceec23dfcf6d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00dc5e1c26ad4f0a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00dc76891bff594a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00dd78ccdb4221fd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00dd8d748fed5007\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00dd9df22bda95cd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00dddcc1f616e3f0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00de672ac66b1283\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00de73055e33cad8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00de8a9cd02ead94\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00defb8436ae67f5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00df15b89bb602f7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00df95c6e27f2c84\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00dfada94844220d\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '00dfcf1cf8fe61d5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e04e5baea17bbb\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e1f088a5d38d27\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e2336d34fb3f96\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e241b734ce3a5f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e25e9a4033f710\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e26a25224a42fc\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '00e2eaad1c2bf049\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e3f344cc9fef4a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e443af94ec9e5f\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e4bd9b06903926\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e4e365cef3f38a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e62171e977b5e7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e63294ad6bd4d7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e6771dff37dd65\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e7b4494b17493d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e7cda69b598e91\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e8e19baaa1891f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e8ebedd6ebc026\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e904aa08008c4a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00e9df65f18ff86b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00e9e884d4068424\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00eab988d5effd62\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00eb06563b988abc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00eb38a698c911fa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00eb84c5fcf528c6\\t1\\t0\\t1\\t0\\t0\\t0',\n",
              " '00ebb4d168b25515\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ebb9189db2e873\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ec7ffc01786b48\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00eccdbe15bc9712\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ee674e6c4017ff\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00ef5c3bdbc4aac7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f04287ddb123d8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f0468189c252b7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f0730335f76284\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f073a9fb7e660d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f0f5160a5d60b1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f14576e729af5e\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f14b4989476638\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f20cef10df7cbe\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f2949f8c5db552\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f294c53a1daba6\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f2c330b028071a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f35270f5811824\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f496156c7ace6b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f4c4e654a41594\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f4cf7142af9955\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f4f27f22e3076f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f5061275635c3a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f5927e2b9586d7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f5961a75d3ed4e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f71457fa67558f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f7b8efa29c290f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f7c652f9395ad2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f7fc6df78cafac\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f815db824089df\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00f868904344da7c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f9807df65a612c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00f9bd16d7e97868\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fa6f5aa87501ea\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00fa82538d807ad1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fad4367999854d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fb7e306b355d9f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fc1d05281a04f9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fcefbf22325873\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '00fdd4ee88010e06\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00fe951918a48e02\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00feb72f1320b8a2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ff78f335f494dd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '00ffc27a419201de\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01008e925d42c443\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0100ec69382951cf\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01011eaabfd0baf5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01014be79661150e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0101e5128e551809\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0102063eba917e84\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01022222f5d271a5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0102d927195b3228\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '010388b55f5f0960\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0103c06877b7421f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0103d9680133eed3\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01045060d37a7a06\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '010619bab9effbf5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01066fc56fb0407c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01069db08a40e197\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0107cf656a9c6b5c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0108cf301fab25af\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0108e1b7a2eeec79\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01092889164725fe\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01092f171012e6e3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01095c394a267197\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010a57587360ed60\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010a621aa40b6e7b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010a8193cb78d02e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010b1cafbd6a2abf\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010b809e4a1f7269\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010c2a979fab2e3f\\t1\\t1\\t1\\t0\\t1\\t0',\n",
              " '010cb1b97a1e7aac\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '010d5ca6df95c7e5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010dd2ec73d11153\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010e151d69aea957\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010e7a11ea1b838b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '010ed76f08f1eb63\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '010f7cd1052dd11e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '010fd153160aaa4b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0110be52b66f4846\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01111ad029e09eae\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01123ff2047b93e7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0112a5434f259543\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0112f42be58819ff\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0113b73e0b5168d8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0113dcc1d0620954\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0113e474b8eb9407\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '1.14509E+14\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0114ae82c53101a9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0114d23ab81d9c63\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0115106609845c3b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0115c1533e83637c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0116351faffcb947\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0116778d9a126d4b\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '0116c96c091f5eb8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0116dc4047101f64\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0117015ec4c12286\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '011747d634437844\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0117a15cf29f1b86\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011841765d69a22e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0118721952b5aae7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0118927d8c536c48\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0118f7ea375be714\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0119b25f6b72bae0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0119d6a08ea286c9\\t1\\t0\\t0\\t0\\t1\\t0',\n",
              " '011a7aeed1435965\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011b51b386c60373\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '011c2d865540bc8d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011c66c760f06436\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '011dbbc4849e6947\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011dc405b347ae93\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011ef0350f96a6a0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '011f0e9104cd6dc9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011f528e733ee014\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '011f5e640910e527\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '011ffb2815e1e747\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0120afbdca1e18dc\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0120f7a24376b785\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01211b4654b54e99\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0121a12d9bc86056\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0121b4195475c300\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0121f89898790454\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01224495d2017d00\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0122538b45e8dd56\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0122c427b6800636\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0122cd5f826207ce\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0122d27c8394a245\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01231ff69280665d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01235dfed8b478f9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0123a46ce36704d9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0123f7c07bedbf0d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0124423d49c95a01\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01246e5b8983045d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01248dc64397eeea\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01264a2810bc4af9\\t1\\t0\\t1\\t0\\t0\\t0',\n",
              " '0126f2609cd2ef7e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012714cce6eb70e5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '012731c65e0f4134\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '012741ebc0230c20\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0127a09b19b34324\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01282bf627e90933\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01285ec78586f747\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01296f38d5d196ed\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01297146fdf8faef\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012973e2771816f7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0129ab10055439ce\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0129ac839d78976e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0129fc214e46ea27\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012b88a9247fbe5d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012c669525c96974\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012c7429c5a34290\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012d31b7f9a3bdb5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012d87c9243d2731\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012e2f8b0b206a14\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012f07c024127807\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '012f268bbbc014c0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012f8118ea74357e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '012ff12b1253601f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01300195ad0237d5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0130e1b878bf9d40\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0131294e4fcea7a1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01319ea40369f7c7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01323d4ad680405b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0132a7784d1762de\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0132d4c88b3369f4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01336e32fdc9beb3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0134382846acc46f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0134c275457df9e0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0134d317454a4624\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0135218693f299d7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0135f14da5942748\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0137500709d8a894\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0137ae56816b36fa\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '0137afba18287c63\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013818151b89fd75\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01381e7421ea8a75\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0138c1892360442e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0139c7daa8d39f77\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0139cba5f682808d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0139e17af9798891\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013b1a8a5a4b3b06\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013b2cd2992bebd0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013b3ddc2ad4e259\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013b96d5b25f99ed\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013ced406e0debc9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013d10e44dfcaafa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013d589460a21393\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013e0243bf44de26\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013e1b7e48e88ead\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013e8950c4c2f006\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '013eb9a980f65eba\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013ebc942230ada4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013eee4cca4baf23\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '013f07bf8b6b1a7f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014054d393c51165\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01407d8e42b73bfa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0140db34aca6a6cf\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014195efc6c2921c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0142392ccfaf1afa\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01423c6a7e307a39\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014245d0406efaaa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0142b5abd8afc286\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0142d32096277776\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014309c7b5657bd8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01431b799014e6aa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01434b266b0daa02\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01458e1707582c48\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0145b9b3d5a03f12\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0145e8020cd6d0e3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0145f4a0b42ebf2f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0146957d45724c62\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014792aa1faaa590\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0147a6d8d95da7c8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01489792a575b1db\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0148c7864d6cb7d2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0148f6939e751cb4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014907f92219c751\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0149191403773c09\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0149a0088f61d457\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014a22a55af8dc32\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014a51b6d59bd3c0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014a6973c0e52b88\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014a9dafac3a92a4\\t1\\t0\\t0\\t0\\t0\\t1',\n",
              " '014af91e832a8e36\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014bcdfcac3f33fa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014c2d8307d7ed7b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014e4300cd18a931\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014e4a9b0b18645f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014e91d7a37d81e6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014eaf08c48e1a14\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014edbfdee84c2e1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '014ee93eb5044da6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014f993ff4590792\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '014fab919f5233c4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015017ec394a264e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01515b1e64cbb3c4\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015160a624805ab5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015161301c1e6868\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0151deff326c8811\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01521ab9bdbe4960\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0152e877f0c35d0e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015303b4549e1e44\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01533b362ba8c4a2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015378076f433901\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0153a8135e7aafd0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0153f7856280e9ad\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0154605a40ddb24d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015474aec031c024\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01548a17138a0da1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0154ae1d551fb649\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0154cc14f8f2a23b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0155555531c8773b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0155602d02ca7051\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0155d282a0ae2760\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '01563e63e55a1cca\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01568d4d84e72ad0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0156b961ccea2858\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0157decfa50311a7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01583c494eaead6c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01596a8f0e0c5a5c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015993840d7dd4f1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0159e946c1678151\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015b2ff3b6f2aa36\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015bbbf22fba4c54\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015c00bc5573b130\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015c103d2ce02f6e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015c182136e881ae\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015cf807c68008ce\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015dc7023208d316\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015de76a6a7e7b08\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015ea0453bacd1db\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015ebdf7498d3955\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015ec956122e1bae\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '015fbe9b6e45559e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '015fcde12b130101\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01609bc52c061fbf\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0160a0bd76873a14\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0160c53391bd9b48\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0160ec78b9b1d8a1\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0161749e0214a64e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0162066f96c40200\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0162c8bd1ee3ae2b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0163035707b24233\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01635643d32446a5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0164123c08c9fcbd\\t1\\t0\\t1\\t0\\t0\\t0',\n",
              " '0164288c47c33601\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01644cf640bafbc0\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0165c9444cb00a9d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0165e972b8f13970\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0166ea16a87a7d1b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01673e9b20aaa1d3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0167520e098406d7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01680b05bde74236\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0168364ae22d4cc2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01683b2e553e0503\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01698aa843d4038e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0169e612340bdfa2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016b04b70538f55d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016b09d531283f37\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016bcb2c70b21eb9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016bf0790d43acb9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016bf6df396e6626\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016bfb52f17ef26c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016ccf2aa9ff18b0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016cf711bae69935\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016da47431bad657\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016da4c4c4a82ba3\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016e34bde0a5a956\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016ea6ffb41b0ba4\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '016eb6aa1b920826\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '016ef8a837c540ed\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0170dbcb6bd2b1a2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01712bccb7c9d283\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017142df13cdf735\\t1\\t0\\t0\\t0\\t0\\t0',\n",
              " '01717a7db1afdd0d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0171b466fa40d87c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0172211bb75870bb\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017236547e058075\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0172883c2fa6290d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01731103b7850e5b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017319eb69e7846b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0173dd710621e443\\t1\\t0\\t1\\t0\\t1\\t0',\n",
              " '0174149ae3f6437c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0174a61dd22b4924\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0176a1870944c863\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0176ef39019262b1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0177b98119d40bd8\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0177debead2cc597\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0177f1d74cbce3e3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017852372ad85be2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017888ccb7977f34\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01790f06b22fa38e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0179189048e1d858\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01795e418bc31027\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017b04df1adb061c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017b30293512bc67\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017b8eb194a3fee5\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017cd1016093f2f7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017cfef4df1c62bd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '017dcba8ba64c529\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017eee07115cd868\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017f8543f378d7f3\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '017fca1c2ef4d277\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01801b04cc86fb28\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01809aa3e3036fd2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0180be6450ef315a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '018252f59c43730d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0182d744dd1d4257\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01834616b403654c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0184253533dfd16c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01842c83b922b07c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0184dbbf2b7da319\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01854a755c310dcf\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018567a851bd4f2e\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01859ff2af295ae2\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0185ac72a68744d8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01861d48e5c9e7c0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01863221a968de14\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01875db3887c7e63\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0187a4a64a68655a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0187f86b335a0b15\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01892180209015b7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01898197b2ecc30d\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0189b99379ff24b7\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0189f00c4a9f4418\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018b09556b7ea3aa\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018b0a898fc20622\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018b1b18f2fb944b\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018b1f370e61c570\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018c408b7f5df7a9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '018d00193f993bbe\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018da48d17a13be2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '018e68acc42b8628\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '018f7faae5117ba6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0190a1dc3d243eb1\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0191179e8af4f773\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0191505e0c2a5fc9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01925347e9fad23f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01928d3471d7e525\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0192e3c7e75e272e\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0193732eb340a943\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01944007a4522d50\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '1.95128E+14\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01953ce07a95be75\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01954198a88a5efc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0195e836d4c4fd6f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0195f0c86c62c6bc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0196398121c8145f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0196928bb2a9a272\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0196d833e95970d2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0196edbfdbd1741c\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0197da40df3f2f1f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0197f30faa81dc6c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '019835bba95970ad\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01984303e7a65619\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '019858d8502a6a3a\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01988cff2b06c3e0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0198962c5435a061\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0198ba1362d90509\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01991332fdc77fa0\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01995f08711456dc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0199b4130247b233\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '0199c9ebb5981799\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '0199e248a8efdce7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '019a2a2e2944ceae\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '019a87aa909546fd\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '019c0cc489063d71\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '019ec7684863d0d7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '019f1ac430b0bcb7\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a01c97d562a4f9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a1cb25f8fb60be\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a30a6496f95428\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a38046de6f0ba6\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a3b93459bf2207\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a3de124e91efc3\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a486143daf1fc6\\t1\\t1\\t1\\t0\\t1\\t1',\n",
              " '01a4862501f687ad\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a4d1dbf1b17994\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a52422bdbd1cf5\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a55d1b91b5afd9\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a5f85d7cb01748\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a6215bdbd7298a\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a6973330afdef9\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a6c133b89d02cc\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a72cb813b1508f\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a73baf9de5a5f8\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a77c4b1ebb4f8f\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a794e35a87c751\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a8471f02a694b2\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a88837abb0119d\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a88fbca211c254\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a89cad34d14eee\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01a8fc8f77480f23\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a90929d9f15973\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a94f05e142c70c\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a988a23a5d9925\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " '01a9ebf72533595b\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01aa8fb1bff7e5cd\\t0\\t0\\t0\\t0\\t0\\t0',\n",
              " '01aafd548fe45134\\t-1\\t-1\\t-1\\t-1\\t-1\\t-1',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1KggMBuEgb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cdc9fad-7b2b-4924-a7a4-a5c1b3ad9eaf"
      },
      "source": [
        "#%cd /content/uncased_L-12_H-768_A-12"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/uncased_L-12_H-768_A-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_whC41uANn5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od2ReLxUO0TU",
        "colab_type": "text"
      },
      "source": [
        "https://huggingface.co/bert-base-uncased\n",
        "https://github.com/huggingface/transformers/issues/643\n",
        "https://www.gitmemory.com/issue/huggingface/pytorch-pretrained-BERT/712/504714891"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozcLlcu9EB9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a7c77965b80c43c3a3e096efcced68dd",
            "dd0349f390ed4f19b86e04578ae991ea",
            "9038bbbca0d643c3a33bb08f30a1a586",
            "e9c9890bb0e74c138719f5a495f6f324",
            "34a675a6cb174d4dabcd6fd83a5f427f",
            "2f34f96bd9bc4968a02f8996d59d3ba9",
            "a96ad69b5d994a95b2b67c84ef4a1625",
            "82c94afbbf9f4fb5878f59901e46140d",
            "1e6bb57707ef44c391b136e2e2a2a175",
            "8491c42539d3462e82668db0c9a0bf16",
            "2f6879bec1544e28ba39fec4cad6050e",
            "701a80bc430a482fb6d85d451924de05",
            "d1e403f08e69497f83ce1430fbc063fa",
            "cc6fd2208223478c9090e28906a528fd",
            "99596628cff44879a50bd023556379d9",
            "00f65e6799ac41aba1b238bd87426577",
            "243bc0364e744804a65c884ad8684ba0",
            "8db5aed8b3ff46f89895a4df7a6602cd",
            "49920be1a20742ae8b72564db7b8fe43",
            "767a342a38a74daab47c5d8644b26987",
            "a2dc55265a4244a881e8fd157267ede4",
            "b1e1f72664fc46028ded53af91ba3bf6",
            "659a675fbc054d60af0cec2d3dd40d07",
            "5bfb25862dd849209671d2b0e2c38a25"
          ]
        },
        "outputId": "1f9d53da-db5c-4c2b-bf86-281c38f8c913"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:22 - INFO - transformers.file_utils -   PyTorch version 1.6.0+cu101 available.\n",
            "08/11/2020 01:51:23 - INFO - transformers.file_utils -   TensorFlow version 2.3.0 available.\n",
            "08/11/2020 01:51:24 - INFO - filelock -   Lock 139890036819280 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "08/11/2020 01:51:24 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpl_yn6kwf\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7c77965b80c43c3a3e096efcced68dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:24 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "08/11/2020 01:51:24 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "08/11/2020 01:51:24 - INFO - filelock -   Lock 139890036819280 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "08/11/2020 01:51:24 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "08/11/2020 01:51:24 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:24 - INFO - filelock -   Lock 139890036819280 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "08/11/2020 01:51:24 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpb26rqe1p\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6bb57707ef44c391b136e2e2a2a175",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:25 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "08/11/2020 01:51:25 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "08/11/2020 01:51:25 - INFO - filelock -   Lock 139890036819280 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "08/11/2020 01:51:25 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "08/11/2020 01:51:26 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "08/11/2020 01:51:26 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "08/11/2020 01:51:26 - INFO - filelock -   Lock 139886006067552 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "08/11/2020 01:51:26 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpb_nntct2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "243bc0364e744804a65c884ad8684ba0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:35 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "08/11/2020 01:51:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "08/11/2020 01:51:35 - INFO - filelock -   Lock 139886006067552 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "08/11/2020 01:51:35 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:51:40 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "08/11/2020 01:51:40 - WARNING - transformers.modeling_utils -   Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uxEZOa7KkH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28533b0e-2343-4b45-af44-6181c1ac31d7"
      },
      "source": [
        "train_examples = None\n",
        "num_train_steps = None\n",
        "if args['do_train']:\n",
        "    train_examples = processor.get_train_examples(args['full_data_dir'], size=args['train_size'])\n",
        "#     train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'])\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 01:57:37 - INFO - __main__ -   LOOKING AT /content/drive/My Drive/Data/toxic_comment_classification_challenge/train.csv\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6sPWY2EKqcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "43d93634-5d1f-461c-ea51-15d6574db3ea"
      },
      "source": [
        "# Prepare model\n",
        "def get_model():\n",
        "#     pdb.set_trace()\n",
        "    if model_state_dict:\n",
        "         model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\", num_labels = num_labels, state_dict=model_state_dict)\n",
        "        #model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
        "    else:\n",
        "        model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\")\n",
        "        #model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "if args['fp16']:\n",
        "    model.half()\n",
        "model.to(device)\n",
        "if args['local_rank'] != -1:\n",
        "    try:\n",
        "        from apex.parallel import DistributedDataParallel as DDP\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    model = DDP(model)\n",
        "elif n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "08/11/2020 01:57:59 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "08/11/2020 01:57:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "08/11/2020 01:57:59 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "08/11/2020 01:58:04 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "08/11/2020 01:58:04 - WARNING - transformers.modeling_utils -   Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2avb5POrtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
        "\n",
        "class CyclicLR(object):\n",
        "    \"\"\"Sets the learning rate of each parameter group according to\n",
        "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
        "    rate between two boundaries with a constant frequency, as detailed in\n",
        "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
        "    The distance between the two boundaries can be scaled on a per-iteration\n",
        "    or per-cycle basis.\n",
        "    Cyclical learning rate policy changes the learning rate after every batch.\n",
        "    `batch_step` should be called after a batch has been used for training.\n",
        "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
        "    This class has three built-in policies, as put forth in the paper:\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        base_lr (float or list): Initial learning rate which is the\n",
        "            lower boundary in the cycle for eachparam groups.\n",
        "            Default: 0.001\n",
        "        max_lr (float or list): Upper boundaries in the cycle for\n",
        "            each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function. Default: 0.006\n",
        "        step_size (int): Number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch. Default: 2000\n",
        "        mode (str): One of {triangular, triangular2, exp_range}.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "            Default: 'triangular'\n",
        "        gamma (float): Constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "            Default: 1.0\n",
        "        scale_fn (function): Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "            Default: None\n",
        "        scale_mode (str): {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle).\n",
        "            Default: 'cycle'\n",
        "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
        "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     for batch in data_loader:\n",
        "        >>>         scheduler.batch_step()\n",
        "        >>>         train_batch(...)\n",
        "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
        "                 step_size=2000, mode='triangular', gamma=1.,\n",
        "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
        "\n",
        "#         if not isinstance(optimizer, Optimizer):\n",
        "#             raise TypeError('{} is not an Optimizer'.format(\n",
        "#                 type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
        "            if len(base_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(base_lr)))\n",
        "            self.base_lrs = list(base_lr)\n",
        "        else:\n",
        "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
        "            if len(max_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(max_lr)))\n",
        "            self.max_lrs = list(max_lr)\n",
        "        else:\n",
        "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.step_size = step_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = self._triangular_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = self._triangular2_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = self._exp_range_scale_fn\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.batch_step(last_batch_iteration + 1)\n",
        "        self.last_batch_iteration = last_batch_iteration\n",
        "\n",
        "    def batch_step(self, batch_iteration=None):\n",
        "        if batch_iteration is None:\n",
        "            batch_iteration = self.last_batch_iteration + 1\n",
        "        self.last_batch_iteration = batch_iteration\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_size = float(self.step_size)\n",
        "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
        "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
        "\n",
        "        lrs = []\n",
        "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
        "        for param_group, base_lr, max_lr in param_lrs:\n",
        "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "            if self.scale_mode == 'cycle':\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            else:\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
        "            lrs.append(lr)\n",
        "        return lrs"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmwpkSWzPeQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "t_total = num_train_steps\n",
        "if args['local_rank'] != -1:\n",
        "    t_total = t_total // torch.distributed.get_world_size()\n",
        "if args['fp16']:\n",
        "    try:\n",
        "        from apex.optimizers import FP16_Optimizer\n",
        "        from apex.optimizers import FusedAdam\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                          lr=args['learning_rate'],\n",
        "                          bias_correction=False,\n",
        "                          max_grad_norm=1.0)\n",
        "    if args['loss_scale'] == 0:\n",
        "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
        "    else:\n",
        "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
        "\n",
        "else:\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args['learning_rate'],\n",
        "                         warmup=args['warmup_proportion'],\n",
        "                         t_total=t_total)\n",
        "\n",
        "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9PcN5uLPjn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval Fn\n",
        "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
        "def eval():\n",
        "    args['output_dir'].mkdir(exist_ok=True)\n",
        "\n",
        "    \n",
        "    eval_features = convert_examples_to_features(\n",
        "        eval_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.float)\n",
        "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    # Run prediction for full data\n",
        "    eval_sampler = SequentialSampler(eval_data)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = label_ids.to('cpu').numpy()\n",
        "#         tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "        tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        if all_labels is None:\n",
        "            all_labels = label_ids.detach().cpu().numpy()\n",
        "        else:    \n",
        "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
        "        \n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "    \n",
        "#     ROC-AUC calcualation\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    for i in range(num_labels):\n",
        "        fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        \n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    result = {'eval_loss': eval_loss,\n",
        "              'eval_accuracy': eval_accuracy,\n",
        "#               'loss': tr_loss/nb_tr_steps,\n",
        "              'roc_auc': roc_auc  }\n",
        "\n",
        "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "#             writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "    return result"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYCAuWSeQNfn",
        "colab_type": "text"
      },
      "source": [
        "Load training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atXFRcdlQOYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = convert_examples_to_features(\n",
        "    train_examples, label_list, args['max_seq_length'], tokenizer)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2cdjAjUQLYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "51ea9ba4-1175-41f2-9ce7-d7248c6ed6fd"
      },
      "source": [
        "logger.info(\"  Num examples = %d\", len(train_examples))\n",
        "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
        "logger.info(\"  Num steps = %d\", num_train_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.float)\n",
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "if args['local_rank'] == -1:\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "else:\n",
        "    train_sampler = DistributedSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 02:06:08 - INFO - __main__ -     Num examples = 159571\n",
            "08/11/2020 02:06:08 - INFO - __main__ -     Batch size = 32\n",
            "08/11/2020 02:06:08 - INFO - __main__ -     Num steps = 19946\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y6Gg983RHoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBObdE_DROmK",
        "colab_type": "text"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQW5qdGhRMRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(num_epocs=args['num_train_epochs']):\n",
        "    global_step = 0\n",
        "    model.train()\n",
        "    for i_ in tqdm(range(int(num_epocs)), desc=\"Epoch\"):\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean() # mean() to average on multi-gpu.\n",
        "            if args['gradient_accumulation_steps'] > 1:\n",
        "                loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "            if args['fp16']:\n",
        "                optimizer.backward(loss)\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
        "    #             scheduler.batch_step()\n",
        "                # modify learning rate with special warm up BERT uses\n",
        "                lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_this_step\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "        logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
        "        logger.info('Eval after epoc {}'.format(i_+1))\n",
        "        eval()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgoXubq2RTxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze BERT layers for 1 epoch\n",
        "#model.module.freeze_bert_encoder()\n",
        "# fit(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwWNUnyeRa0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a38503f6-fa8c-49c7-b5c6-5049dcf6489e"
      },
      "source": [
        "model.module.unfreeze_bert_encoder()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e5502767395c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze_bert_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'BertForMaskedLM' object has no attribute 'module'"
          ]
        }
      ]
    }
  ]
}
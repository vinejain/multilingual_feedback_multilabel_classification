{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_CFA_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinejain/multilingual_feedback_multilabel_classification/blob/master/BERT_CFA_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt4sr6P-wC7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b3c36f56-b162-4154-b185-323023300218"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/6b/e705f03eb23b9002d01b942423d3e5f954acd9b20d9dfd5ee25868f44893/bert_tensorflow-1.0.3-py2.py3-none-any.whl (68kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWiS36j18E62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7f7ba59-a8f5-4810-87ee-a56c77626cbb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7imIW85JOMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "80d0ed6d-a152-49a1-9400-7f56a7183571"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.33)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.33)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkEsRHdV8fUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "134daecf-4d4a-4156-8b42-9232083c57c5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQwpsvpJck2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97629096-12be-4078-e68b-5b4ea4fad5da"
      },
      "source": [
        "pip install apex"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting apex\n",
            "  Downloading https://files.pythonhosted.org/packages/31/b6/923de12ffcc2686157d7f74b96396b87c854eaaeec9d441d120facc2a0e0/apex-0.9.10dev.tar.gz\n",
            "Collecting cryptacular\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/d6/a82d191ec058314b2b7cbee5635150f754ba1c6ffc05387bc9a57efe48b8/cryptacular-1.5.5.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/83/459decec1dd2c14d60f9a360fff989c128abe545a1554a1da64b054a55d4/zope.sqlalchemy-1.3-py2.py3-none-any.whl\n",
            "Collecting velruse>=1.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/d9/e18b5c98667c45f5dd1a256d72168ea5ff68f0025fc5b24be010f2696ca3/velruse-1.1.1.tar.gz (709kB)\n",
            "\u001b[K     |████████████████████████████████| 716kB 8.5MB/s \n",
            "\u001b[?25hCollecting pyramid>1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/4f/6fe39af43fadc6d6c12f4cff9ed438f4fed20245614170959b38fe9f762d/pyramid-1.10.4-py2.py3-none-any.whl (325kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 20.4MB/s \n",
            "\u001b[?25hCollecting pyramid_mailer\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/c3/0ce593179a8da8e1ab7fe178b0ae096a046246bd44a5787f72940d6dd5b2/pyramid_mailer-0.15.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from apex) (2.23.0)\n",
            "Collecting wtforms\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/31/614fc7dc7d76005b0acb8c0c8920d962b83d7422b4ba912886dfb63f86ff/WTForms-2.3.3-py2.py3-none-any.whl (169kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 19.5MB/s \n",
            "\u001b[?25hCollecting wtforms-recaptcha\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/b0/42021ab061b768e3e5f430466219468c2afec99fe706e4340792d7a6fab4/wtforms_recaptcha-0.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from cryptacular->apex) (49.2.0)\n",
            "Collecting pbkdf2\n",
            "  Downloading https://files.pythonhosted.org/packages/02/c0/6a2376ae81beb82eda645a091684c0b0becb86b972def7849ea9066e3d5e/pbkdf2-1.3.tar.gz\n",
            "Collecting zope.interface>=3.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 19.5MB/s \n",
            "\u001b[?25hCollecting transaction>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/06/17b311f04ee623bea66f2f2a93a1b5691e383278d7d30980bba3f1c03ce9/transaction-3.0.0-py2.py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=0.7 in /usr/local/lib/python3.6/dist-packages (from zope.sqlalchemy->apex) (1.3.18)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from velruse>=1.0.3->apex) (1.3.0)\n",
            "Collecting anykeystore\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/dc/c4399c0e6b835710763705220f9c37681683f950678db799a5c7eda9e154/anykeystore-0.2.tar.gz\n",
            "Collecting python3-openid\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/a5/c6ba13860bdf5525f1ab01e01cc667578d6f1efc8a1dba355700fb04c29b/python3_openid-3.2.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 22.0MB/s \n",
            "\u001b[?25hCollecting translationstring>=0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/98/36187601a15e3d37e9bfcf0e0e1055532b39d044353b06861c3a519737a9/translationstring-1.4-py2.py3-none-any.whl\n",
            "Collecting plaster-pastedeploy\n",
            "  Downloading https://files.pythonhosted.org/packages/11/c4/0470056ea324c7a420c22647be512dec1b5e32b1b6e77e27c61838d2811c/plaster_pastedeploy-0.7-py2.py3-none-any.whl\n",
            "Collecting webob>=1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/3c/de37900faff3c95c7d55dd557aa71bd77477950048983dcd4b53f96fde40/WebOb-1.8.6-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 25.8MB/s \n",
            "\u001b[?25hCollecting plaster\n",
            "  Downloading https://files.pythonhosted.org/packages/61/29/3ac8a5d03b2d9e6b876385066676472ba4acf93677acfc7360b035503d49/plaster-1.0-py2.py3-none-any.whl\n",
            "Collecting zope.deprecation>=3.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/26/b935bbf9d27e898b87d80e7873a0200cebf239253d0afe7a59f82fe90fff/zope.deprecation-4.4.0-py2.py3-none-any.whl\n",
            "Collecting venusian>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/43/92/3d522a710867168ee422a0ffbd712c425ece937aaeec4381497a59e24faf/venusian-3.0.0-py3-none-any.whl\n",
            "Collecting hupper>=1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/48/7f/06ace28143b2cb3a4b14c9d9e5165741d2d133ef331b616acf47ab5c3517/hupper-1.10.2-py2.py3-none-any.whl\n",
            "Collecting repoze.sendmail>=4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/98/c5c64dc045b7c45858c391d04673a0f2748acef8e0eea4f2989b22220f97/repoze.sendmail-4.4.1-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from wtforms->apex) (1.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from python3-openid->velruse>=1.0.3->apex) (0.6.0)\n",
            "Collecting PasteDeploy>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/18/196e5070ced83bb81edd83c79545232d1d2ec55e3a099a146a3333244a6b/PasteDeploy-2.1.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: cryptacular\n",
            "  Building wheel for cryptacular (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.5.5-cp36-abi3-manylinux2010_x86_64.whl size=47550 sha256=e2e85dfc5eedd361c11c752d722262519a957d090fc4997bbcf7d2f4e8542dd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/79/bc/1eec7120c3ff9b0a2c7ad94d1626abc3388688e2ed7a45878f\n",
            "Successfully built cryptacular\n",
            "Building wheels for collected packages: apex, velruse, pbkdf2, anykeystore\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-cp36-none-any.whl size=46467 sha256=d2ef917e45c392ff96ee05fb7c2b19fab12404b3e4c3264c5605741aab76e41a\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/4c/4b/2990cf86a29c679ae4bd5f4de5723aa8a4af107721089c9a55\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-cp36-none-any.whl size=50924 sha256=f01e0165975d4642359b50382489abb225f3ed0c08497b4eff2eee1f7efc2893\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/65/9e/b805aad8ec3a359591c497b257dabe911f305d285b5d8a13cc\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-cp36-none-any.whl size=5103 sha256=092f36589f3e6b9bb410e42b01de6e3d3b4f3c87ae1a749ef3ac8cc81bf565d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/62/b9/0bf3a68f2111e169253ec4d2bbdc303c46777b7fc99bbbf230\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-cp36-none-any.whl size=17026 sha256=d821b3b1ee356eee458ec8ba9cce6e0127d6b3c6f60cc45326c82babfacfeb32\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/a9/b2/f79f84cbee6613c9edce6d98b9e1410c1d41d38953bd94eed2\n",
            "Successfully built apex velruse pbkdf2 anykeystore\n",
            "Installing collected packages: pbkdf2, cryptacular, zope.interface, transaction, zope.sqlalchemy, translationstring, PasteDeploy, plaster, plaster-pastedeploy, webob, zope.deprecation, venusian, hupper, pyramid, anykeystore, python3-openid, velruse, repoze.sendmail, pyramid-mailer, wtforms, wtforms-recaptcha, apex\n",
            "Successfully installed PasteDeploy-2.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.5.5 hupper-1.10.2 pbkdf2-1.3 plaster-1.0 plaster-pastedeploy-0.7 pyramid-1.10.4 pyramid-mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-3.0.0 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.6 wtforms-2.3.3 wtforms-recaptcha-0.3.2 zope.deprecation-4.4.0 zope.interface-5.1.0 zope.sqlalchemy-1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df0EAyb8ot3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "438d9b0c-3cf6-45be-9825-9b424ecb56ce"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bzRcy6nL57J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "66aa815b-b6a4-4781-c161-23b10ccd0a0e"
      },
      "source": [
        "#pip uninstall apex"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling apex-0.9.10.dev0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/apex-0.9.10.dev0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/apex/*\n",
            "Proceed (y/n)? n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu4baW6eL_a-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "63ce738c-ecdc-44b5-fe38-c018842dafde"
      },
      "source": [
        "!git clone https://www.github.com/nvidia/apex"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "warning: redirecting to https://github.com/nvidia/apex.git/\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 7425 (delta 7), reused 3 (delta 1), pack-reused 7400\u001b[K\n",
            "Receiving objects: 100% (7425/7425), 13.92 MiB | 23.71 MiB/s, done.\n",
            "Resolving deltas: 100% (5005/5005), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGCNm5T8tzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e59aa9b-5472-4ee7-938d-167388967aef"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVQV_GiMP39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b759083-b9f0-4693-f075-b5bc49fa26c7"
      },
      "source": [
        "cd apex"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em9Br06HMQUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebe14a94-2a30-4182-b63f-f10160c0794f"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Warning: Torch did not find available GPUs on this system.\n",
            " If your intention is to cross-compile, this is not an error.\n",
            "By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
            "Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
            "and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
            "If you wish to cross-compile for a single specific architecture,\n",
            "export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
            "\n",
            "\n",
            "\n",
            "torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating apex.egg-info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/apex\n",
            "copying apex/__init__.py -> build/lib/apex\n",
            "creating build/lib/apex/normalization\n",
            "copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "creating build/lib/apex/pyprof\n",
            "copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "creating build/lib/apex/amp\n",
            "copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "creating build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "creating build/lib/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "creating build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "creating build/lib/apex/mlp\n",
            "copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "creating build/lib/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "creating build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "creating build/lib/apex/RNN\n",
            "copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "creating build/lib/apex/contrib\n",
            "copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "creating build/lib/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "creating build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "creating build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "creating build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "creating build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "creating build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "creating build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "creating build/lib/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "creating build/lib/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-36: module references __path__\n",
            "creating dist\n",
            "creating 'dist/apex-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg\n",
            "Extracting apex-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Finished processing dependencies for apex==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov3SFh6_KCZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zope.interface import implementer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0udgtsLIqqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import pdb\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import apex\n",
        "from sklearn.model_selection import train_test_split\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3JmRFJbPNpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "9174baa7-1630-428c-b024-8290685fcf66"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForNextSentencePrediction\n",
        "\n",
        "BERT_CLASS = BertForNextSentencePrediction"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.33)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.33->boto3->pytorch_pretrained_bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGDJ_jwjPT8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3a4d165b-e906-443a-9b97-dc9f898f4401"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU1HkjYK262n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "ec6351f1-b603-4533-807f-6e8709f8b346"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "!unzip the file\n",
        "!unzip cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 00:39:22--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 172.217.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M   126MB/s    in 3.1s    \n",
            "\n",
            "2020-08-11 00:39:25 (126 MB/s) - ‘cased_L-12_H-768_A-12.zip’ saved [404261442/404261442]\n",
            "\n",
            "unzip:  cannot find or open the, the.zip or the.ZIP.\n",
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "   creating: cased_L-12_H-768_A-12/\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrEvpeXC3A4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a509b5b7-d2cb-4c22-d340-19bd73a7efee"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex\t\t\t   csrc      README.md\n",
            "apex.egg-info\t\t   dist      requirements_dev.txt\n",
            "build\t\t\t   docs      requirements.txt\n",
            "cased_L-12_H-768_A-12\t   examples  setup.py\n",
            "cased_L-12_H-768_A-12.zip  LICENSE   tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd8oIUg67ezi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ac76304-bd47-414f-e5a5-2ff64db29172"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52228zog-Kt4",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/51417533/stuck-in-datalab-directory-cant-navigate-to-my-desired-directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxe5jaSL7iDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b680d08-13a3-4913-d1cd-ca1496495c1e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMTnm8BzMzPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA_PATH=Path('../Toxic_comment/')\n",
        "DATA_PATH=Path('/content/drive/My Drive/Data/toxic_comment_classification_challenge/')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "#PATH=Path('../Toxic_comments/')\n",
        "PATH=Path('/content/drive/My Drive/Data/toxic_comment_classification_challenge/')\n",
        "PATH.mkdir(exist_ok=True)\n",
        "\n",
        "CLAS_DATA_PATH=PATH/'class'\n",
        "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "model_state_dict = None\n",
        "\n",
        "# BERT_PRETRAINED_PATH = Path('../trained_model/')\n",
        "#BERT_PRETRAINED_PATH = Path('/content/drive/My Drive/Toxic_comment/uncased_L-12_H-768_A-12/')\n",
        "BERT_PRETRAINED_PATH = Path('/content/uncased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/cased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/uncased_L-24_H-1024_A-16/')\n",
        "\n",
        "\n",
        "# BERT_FINETUNED_WEIGHTS = Path('../trained_model/toxic_comments')\n",
        "\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH\n",
        "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)\n",
        "\n",
        "# output_model_file = os.path.join(BERT_FINETUNED_WEIGHTS, \"pytorch_model.bin\")\n",
        "\n",
        "# Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQPLIcmUM368",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "args = {\n",
        "    \"train_size\": -1,\n",
        "    \"val_size\": -1,\n",
        "    \"full_data_dir\": DATA_PATH,\n",
        "    \"data_dir\": PATH,\n",
        "    \"task_name\": \"toxic_multilabel\",\n",
        "    \"no_cuda\": False,\n",
        "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
        "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
        "    \"max_seq_length\": 512,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"eval_batch_size\": 32,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"num_train_epochs\": 4.0,\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"no_cuda\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"seed\": 42,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"optimize_on_cpu\": False,\n",
        "    \"fp16\": False,\n",
        "    \"loss_scale\": 128\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6KwClElf5a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm5E8JOof9eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14cgH-_Tf_96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError() \n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3R9Gvj1gEZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "    \n",
        "    \n",
        "    def get_train_examples(self, data_dir, size=-1):\n",
        "        filename = 'train.csv'\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"train\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"train\")\n",
        "        \n",
        "    def get_dev_examples(self, data_dir, size=-1):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        filename = 'val.csv'\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"dev\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None)[0].values)\n",
        "            #self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"test_labels.csv\"),header=None)[0].values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=True):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[0]\n",
        "            text_a = row[1]\n",
        "            if labels_available:\n",
        "                labels = row[2:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKgB3wGXgH9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(float(label))\n",
        "\n",
        "#         label_id = label_map[example.label]\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBTK8WpgMJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqQKucagPNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)\n",
        "\n",
        "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "\n",
        "\n",
        "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
        "    \"Computes the f_beta between `preds` and `targets`\"\n",
        "    beta2 = beta ** 2\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    y_pred = (y_pred>thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    TP = (y_pred*y_true).sum(dim=1)\n",
        "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
        "    rec = TP/(y_true.sum(dim=1)+eps)\n",
        "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
        "    return res.mean().item()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiT4QUhPgR8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GZEwawagT1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "084ddc36-8529-4982-8981-89b3a8a9ce4a"
      },
      "source": [
        "processors = {\n",
        "    \"toxic_multilabel\": MultiLabelTextProcessor\n",
        "}\n",
        "\n",
        "# Setup GPU parameters\n",
        "\n",
        "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "#     n_gpu = 1\n",
        "else:\n",
        "    torch.cuda.set_device(args['local_rank'])\n",
        "    device = torch.device(\"cuda\", args['local_rank'])\n",
        "    n_gpu = 1\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
        "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08/11/2020 00:44:55 - INFO - __main__ -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLmOKpR7gV8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwVbVbB2gZXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args['seed'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4evhA1KgcOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_name = args['task_name'].lower()\n",
        "\n",
        "if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrmsZzDmgeVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processor = processors[task_name](args['data_dir'])\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib8pjuuOhtQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}